role,content
system,"Given an article text delimited with triple back-ticks, analyze the article and identify three tags that best summarize its main topics. These tags should reflect the key technologies, concepts, and themes covered in the article. 

Adhere to these steps for consistency and accuracy:
- If the article mentions several technologies or themes, focus on those that are central to the main argument or purpose of the article.
- If a technology or theme is mentioned in multiple significant contexts, it should be considered more relevant.
- Avoid selecting tags that are only briefly mentioned or not central to the article's main points. 
- Only choose from the list of possible tags provided below:
LIST OF POSSIBLE TAGS:
Serverless, Landing Zone, RDS, DynamoDB, Lambda, Control Tower, Multi-AZ, Read Replica, Disaster Recovery, Data Modeling, Performance, Scalability, Cost Optimization, Security, Governance, Observability, Monitoring, DevOps, Machine Learning, Artificial Intelligence, Software Development
OUTPUT FORMAT:
- LIST OF TAGS: List the 3 most relevant tags in a simple JSON array."
user,"Analyze the article and identify three tags that best summarize its main topics
ARTICLE TEXT:
```
The most exciting thing in the Cloud is serverless technology.
Whether you are a small business or a giant multinational corporation, getting into serverless application architectures is absolutely one of the best investments you can make for your organization. With serverless, you can unlock incredible, order-of-magnitude lower operating costs for your applications, without sacrificing reliability, performance, scalability and security.
Why Serverless? Cost-Efficiency!
The infographic above shows the result of a cost experiment I did. I created a 100% serverless web app (will discuss the architecture shortly), and then ran automated API calls and page retrievals against it to simulate a reasonably heavy, month-long workload. The bill for the entire serverless web app did not even reach $5.
This is the most compelling reason for you to act towards serverless computing for your org. For most use cases, nothing beats a truly serverless application architecture when it comes to cost efficiency - and that's not at the expense of scalability, reliability, performance and security. Going deep into these other factors is beyond the scope of this article, but suffice it to say, when most of the reliability, scalability, performance and security are offloaded to the hyperscaler, you generally get a better experience than if you had to manage those yourself - and that's exactly the reality in serverless.
Basic Serverless Web Application Architecture
Above, you can see the basic serverless architecture that resulted in the insane cost-efficiency I just mentioned.
Let's step through the architecture quickly:
A user accesses your web application through his browser
His browser requests and receives web files (HTML / CSS / JS / images / etc.) from an S3 bucket that is configured for static web hosting. Essentially, this is like Apache/httpd in the old web world.
Once the page loads in his browser, dynamic API calls (c/o JavaScript) fire in response to events (such as button clicks, or even just the page loading completely). These API calls hit your API Gateway endpoints.
Your API Gateway uses a Lambda Authorizer to verify if the API request should be honored. When the Lambda Authorizer confirms, API Gateway then routes the request to the appropriate backend service, which is composed of Lambda functions.
Your Lambda functions work on the request. For non-trivial systems, these mostly mean querying a database and doing some pre- or post-processing. In this architecture, that database is DynamoDB.
DynamoDB executes the query, responds back to the Lambda function, and the response is then sent back to the user's browser as an API Gateway response.

That's essentially what's happening. It's a typical, run-of-the-mill business system in web app form, nothing sexy or exciting about it.
What is sexy and exciting, though, is the cost. If you implemented this same architecture using traditional old-school cloud architecture (say, EC2 + ALB for high availability, running the LAMP stack), it'd cost you about $150 a month instead of <$5. (Metric: a busy system that has 1,000+ data encoding transactions and 4,000+interactions every hour)
Not only are you paying much more, that EC2 + ALB setup is NOT more reliable, NOT more secure, and NOT more scalable than the basic serverless web app architecture. It's pretty much a no-win scenario for an EC2 deployment here.
Wrap up
This article's goal is to evangelize the wonders of serverless, and I hope that's what you're taking away so far. Hopefully, this motivates you to take a deeper look into serverless, if you aren't a convert yet.
In a future article, we'll deep dive into actually implementing such an architecture.
```"
assistant,"[""Serverless"", ""Lambda"", ""Cost Optimization""]"
system,"Given an article text delimited with triple back-ticks, analyze the article and identify three tags that best summarize its main topics. These tags should reflect the key technologies, concepts, and themes covered in the article. 

Adhere to these steps for consistency and accuracy:
- If the article mentions several technologies or themes, focus on those that are central to the main argument or purpose of the article.
- If a technology or theme is mentioned in multiple significant contexts, it should be considered more relevant.
- Avoid selecting tags that are only briefly mentioned or not central to the article's main points. 
- Only choose from the list of possible tags provided below:
LIST OF POSSIBLE TAGS:
Serverless, Landing Zone, RDS, DynamoDB, Lambda, Control Tower, Multi-AZ, Read Replica, Disaster Recovery, Data Modeling, Performance, Scalability, Cost Optimization, Security, Governance, Observability, Monitoring, DevOps, Machine Learning, Artificial Intelligence, Software Development
OUTPUT FORMAT:
- LIST OF TAGS: List the 3 most relevant tags in a simple JSON array."
user,"Analyze the article and identify three tags that best summarize its main topics
ARTICLE TEXT:
```
You've probably heard ""landing zones"" mentioned at some point or another if you work even just tangentially in the Cloud industry. It sounds very important, and even sort-of, kind-of military-ish. So what the heck exactly is a landing zone in the Cloud, and why should you care?
What does ""landing zone"" even mean?
In the military, a landing zone (LZ) is literally a pad or area where aircraft (especially helicopters) can land. If there is an LZ in an area, then you know that everyone being airlifted to the area will land and start at the exact same place - the LZ. It doesn't matter if we're airlifting new personnel, medical supplies, or arms and ammunition. They all land and start their life in that new area on the LZ, where we know it is secure and necessary support operations are in place.
The Cloud co-opted that terminology because it describes what we want to accomplish when it comes to scaling Cloud adoption and governance. We want every single Cloud account, across all the business units (BUs) of an organization, to start at the exact same, predefined starting point.
We want to make sure every new account follows the same baseline security guidelines and best practices, and have access to the same basic building blocks as everybody else.
How does a landing zone help me?
At their core, Cloud landing zones are a scalable and secure configuration to make complex Cloud environments (read: Enterprise-level, multi-account environments) easier to govern and, just as critically, easier to adopt.
Landing zones are meant to help two distinct general Cloud stakeholders, which we can loosely identify as ""admins"" and ""consumers"":
Admins: For those that are ultimately responsible for the administration of Cloud accounts, a landing zone approach makes it easier for them to centrally manage and govern the entirety of their multi-account environment.
Consumers: These are the general Cloud users in an organization. They might be developers who create applications in the Cloud, or they might simply be users who need to deploy specific infrastructure (VMs, storage, databases…).
Typically, consumers are interested only in consuming Cloud services. This is a problem, because that means they usually don't care about (and are also typically not trained for) security and compliance in the Cloud. So if important aspects of Cloud usage (like security, cost and various other policy compliance) are left to the goodwill of consumers, well… that multi-account environment you have is headed for a really bad nightmare.
And this is why landing zones are essential.
An LZ helps the Cloud admins by giving them centralized management of their multi-account environment, with baselines and automations baked-in. Security and service controls for each new account created, for example, means Cloud admins will have the peace of mind knowing that consumers in every account are automatically following these security and service controls, because their creation and enforcement are automatic.
An LZ helps the Cloud consumers, too, because now they can focus on their work, instead of (for example) figuring out how to implement an encrypted, centralized Cloud audit trail so that IT Audit won't yell at them next year. They know the landing zone is already set up so that all necessary security and governance baselines are in place - with no effort on their end.
It's a win-win.
AWS Landing Zone vs AWS Control Tower
Something that used to generate a ton of confusion needs a bit of mention: AWS Landing Zone.
So earlier, we were talking about a ""landing zone"" (small letter ""L"", small letter ""Z""; generic)
There is also something called the ""AWS Landing Zone"" (capital ""L"", capital ""Z""; specific), which, pre-2019, was the de facto way to create a landing zone in AWS. This wasn't really a service - instead, AWS Landing Zone is an ""AWS Solution"", which you can think of basically as a quick start package - IaC templates, code, and configuration to deploy a landing zone. AWS Landing Zone is currently in ""Long-term Support"", which is AWS-speak for ""you can keep using this, but it won't be getting any new features and updates anymore, because you should be using something else.""
Post-2019, the recommended way to create landing zones in AWS is AWS Control Tower. This is an actual AWS service, not just a ""solution"". Essentially, it service-ified AWS Landing Zone, making it easier to deploy, and easier to manage. Analogously, you can think of it as the jump from using IaaS (Infra as a Service) to suddenly using PaaS (Platform as a Service) - what you used to have to tinker with at a very low level to get anything done is now abstracted for you, with a lot of heavy lifting removed.
Wrap up
This was just a short introduction to landing zones, to get you to understand the spirit of them, why they matter, and some disambiguation between the AWS Landing Zone solution and AWS Control Tower.
In a future article, we'll go a bit deeper into the design of landing zones and the common problems these design decisions solve.
```"
assistant,"[""Landing Zone"", ""Control Tower"", ""Governance""]"
system,"Given an article text delimited with triple back-ticks, analyze the article and identify three tags that best summarize its main topics. These tags should reflect the key technologies, concepts, and themes covered in the article. 

Adhere to these steps for consistency and accuracy:
- If the article mentions several technologies or themes, focus on those that are central to the main argument or purpose of the article.
- If a technology or theme is mentioned in multiple significant contexts, it should be considered more relevant.
- Avoid selecting tags that are only briefly mentioned or not central to the article's main points. 
- Only choose from the list of possible tags provided below:
LIST OF POSSIBLE TAGS:
Serverless, Landing Zone, RDS, DynamoDB, Lambda, Control Tower, Multi-AZ, Read Replica, Disaster Recovery, Data Modeling, Performance, Scalability, Cost Optimization, Security, Governance, Observability, Monitoring, DevOps, Machine Learning, Artificial Intelligence, Software Development
OUTPUT FORMAT:
- LIST OF TAGS: List the 3 most relevant tags in a simple JSON array."
user,"Analyze the article and identify three tags that best summarize its main topics
ARTICLE TEXT:
```
There are important differences between RDS Multi-AZ deployments and Read Replicas. This article will clarify the different benefits of each, when you should use them, and even how to use them together.
Read Replicas
Benefits of read replicas:
Provide extra database compute performance (for read-only queries).
Protect your primary DB's critical transactions from read surges.
Isolate different read-only workloads - for example, separate read replicas for different reporting modules, to isolate heavy users from others.
Provide some failover capability - manual promotion to primary during a disaster, with AZ-level reliability.

If you are primarily looking for a way to scale performance, and you are ok doing manual failover during disasters, Read Replicas are an excellent balance between performance and availability.
If you need a recap of what read replicas are and more in-depth information, here's my old article on read replicas.
Multi-AZ Deployments
Benefits of Multi-AZ deployments:
Synchronous replication between primary and standby. This is the best guarantee you have for making sure every data that gets committed to your primary also gets to your secondary as well - a guarantee that isn't as strong when it comes to the asynchronous replication used in read replicas.
Automated, most hassle-free DR option. In a disaster, the last thing you want to be doing is fiddling with endpoints and doing a manual failover. RDS Multi-AZ is your best friend here, handling that failover for you quickly and without any manual intervention.

If your primary concern is reliability and disaster recovery, and aren't really concerned about scaling read performance, then Multi-AZ is the better option.
If you are looking for more in-depth information about RDS Multi-AZ deployments, here's my old article on the topic.
Multi-AZ + Read Replica Combo
If you need to scale performance without sacrificing synchronous replication and painless failover, you can combine Multi-AZ deployments with read replicas.
In the architecture above, you end up paying 3x the cost of a single Primary instance, but it's a powerful combo of getting extra performance without sacrificing the data durability of synchronous replication and automatic failover.
For heavy mission-critical workloads, combining Multi-AZ and Read Replicas - instead of choosing one over the other - is a viable option.
Wrap Up
So, Multi-AZ, Read Replica, or both?
If you are only looking to solve performance problems: Read Replica.
If you are only looking to solve data durability and painless failover: Multi-AZ
If you are managing a highly mission-critical workload that needs both performance scaling and the highest levels of data durability and reliability: Combine Multi-AZ and Read Replicas.
```"
assistant,"[""RDS"", ""Multi-AZ"", ""Disaster Recovery""]"
system,"Given an article text delimited with triple back-ticks, analyze the article and identify three tags that best summarize its main topics. These tags should reflect the key technologies, concepts, and themes covered in the article. 

Adhere to these steps for consistency and accuracy:
- If the article mentions several technologies or themes, focus on those that are central to the main argument or purpose of the article.
- If a technology or theme is mentioned in multiple significant contexts, it should be considered more relevant.
- Avoid selecting tags that are only briefly mentioned or not central to the article's main points. 
- Only choose from the list of possible tags provided below:
LIST OF POSSIBLE TAGS:
Serverless, Landing Zone, RDS, DynamoDB, Lambda, Control Tower, Multi-AZ, Read Replica, Disaster Recovery, Data Modeling, Performance, Scalability, Cost Optimization, Security, Governance, Observability, Monitoring, DevOps, Machine Learning, Artificial Intelligence, Software Development
OUTPUT FORMAT:
- LIST OF TAGS: List the 3 most relevant tags in a simple JSON array."
user,"Analyze the article and identify three tags that best summarize its main topics
ARTICLE TEXT:
```
DynamoDB and its NoSQL brethren are essentially infinitely scalable thanks to the power of horizontal scaling, as I explained in a previous article. (That old article is worth a read if you're interested in finding out how they implemented the magic behind the scenes!)
But there's a big caveat there: it scales infinitely and offers blazing performance at any scale if you properly model your data.
This is part 3 of this series, where we will deal with handling hierarchical classification. (Here are Part 1 and Part 2 if you're new to the series and want to get caught up)
Where we left off from Part 2
In part two, we talked about the power of sparse indexes. We went through how they can be used to transform this:
… into this:
… so that we can more efficiently query and sort active orders from DynamoDB, without needing to waste time and money reading inactive orders at all.
And of course, keeping with our Single-Table Design paradigm, our generic sparse index can accommodate multiple tables with the same active/inactive access pattern.
Scenario: A hierarchical data classification, and the need to lookup at different levels of the hierarchy
We left Part 2 with the following scenario:
If we had such a table like above, and we often need to query for the airports per country, or per state, or per city, how do we model that in a single DynamoDB table?
The problem in more detail
Let's make sure we understand the problem here before we try to solve it.
We can easily turn this into a Single-Table DynamoDB deployment by doing something like this:
This type of design is consistent with what we've learned from Part 1, and this means we now have a ""virtual table"" that contains all this airport data in our DynamoDB table, along with any number of other ""virtual tables"" we may have.
Here's where this breaks down:
Querying for all airports in the USA (through GSI1) will mean having to do a FILTER against the Country field, which is not a key attribute, so the entire contents of our airport ""virtual table"" will be read.
Querying for all airports in the state of California (through GSI1) will mean having to do a FILTER against the State field, which is not a key attribute, so the entire contents of our airport ""virtual table"" will be read.
Querying for all airports in the city of Los Angeles (through GSI1) will mean having to do a FILTER against the City field, which is not a key attribute, so the entire contents of our airport ""virtual table"" will be read.

We already encountered this type of problem in Part 2, so we know that if we ever do a filter operation (i.e., using a filter condition), we might end up reading (and paying for) a ton of data that we don't really need. If we only wanted to find the airports in Los Angeles, for example, we really don't want to have to go through the entire list of ALL airports in ALL countries.
That's the core of this problem. We already know how to easily turn our Airports table into a ""virtual table"" in our Single-Table DynamoDB. Now we need to increase our skills to also be able to deal with a multi-level, hierarchical classification access pattern.
Dealing with hierarchical classification data
Here's what we can do to accommodate this hierarchical data access pattern:
You probably noticed that not only did we remove the individual Country / State / City fields, we also made ""gs1-sk"" contain something else other than just a copy of the ""pk"" field.
That shouldn't be totally strange. Although since Part 1 our ""gsi1-sk"" field contained just a copy of the ""pk"" field, it's only because it was what we needed to make our ""virtual tables"" work. If needed, we could always put a different value there, and now we did.
Given the new table above, we can now do the following queries:
GSI1 index queries:
sk=""airport"", gs1-sk begins_with ""USA"" -> get all airports in the USA
sk=""airport"", gs1-sk begins_with ""USA#CA"" -> get all airports in California
sk=""airport"", gs1-sk = ""USA#CA#LA"" -> get all airports in Los Angeles
sk=""airport"" -> get all airports

Now we've actually solved this scenario's core problem - querying for airports at different levels of the hierarchical classification, without resorting to a filter condition.
Hierarchical classification data is everywhere
You might be thinking, ""Yeah, cool trick, JV, but I'm not really ever going to be managing a list of airports, so I'm not really going to benefit from this data modeling technique!""
But hold on there!
Hierarchical classification data is everywhere. Let's take a more mundane example that most corporate programmers will likely encounter: Inventory data
Above is an example of inventory of assets, with a three-tier classification. The data there isn't real, of course, but that's essentially what a lot of inventory or asset systems you've encountered look like.
And there's also nothing special about being a three-tier classification system. 3 just happens to be a convenient number that gives enough flexibility without being too difficult for humans to manage (but you will no doubt encounter 4 or 5-tier ones, too, but more rarely).
No matter how many tiers are in the hierarchy, we model exactly like we previously have:
And this would work exactly like our airport ""virtual table"", where we can query, for example, for all furniture, or all equipment, or any level of subtypes within them, such as ""all mechanical equipment"" or ""all one-door cabinets""
What else other than inventory could typically use hierarchical classification? Well, does your business or application keep track of users, customers or suppliers based on geography - say, continent/region and country? That's a two-level hierarchical classification!
Wrap up
Hierarchical classification data is everywhere. Now you know how to efficiently deal with them in DynamoDB, giving you the best performance and best (lowest) cost.
Next week, in Part 4 of this series, we'll tackle the issue of breaking up vs. consolidating data - an issue that affects both performance and cost.
```"
assistant,"[""DynamoDB"", ""Performance"", ""Cost Optimization""]"
